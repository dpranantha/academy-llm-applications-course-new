{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fdcd6e0a3ab320c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 1 - Basic prompt engineering\n",
    "The goal of this exercise is to become familiar with the basic prompt engineering techniques.\n",
    "We do this by first interactively exploring the examples from the slides.\n",
    "Then, we will apply the same techniques to extract information from a dataset of housing descriptions.\n",
    "\n",
    "Before we start, let's import the necessary libraries and create a client for the Azure OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf5960f5b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_in_production.openai_utils import get_openai_client\n",
    "import dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "# Here we create the client.\n",
    "client = get_openai_client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14055929d19b83e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1a: Examples from the slides\n",
    "In this exercise, you can interactively re-run the examples from the slides.\n",
    "We have implemented these examples using both the text completion and chat API.\n",
    "\n",
    "\n",
    "For each of the examples, do the following:\n",
    "- First, just run the example and see what happens.\n",
    "- Then, compare the prompts for text completion and chat API. How are they different?\n",
    "- Afterwards, modify the prompt to see how it affects the output.\n",
    "- Optionally, you can try to give it a different problem and see if it still works.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be2dc1dbc2852c80",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Classification\n",
    "Here we show a prompt that transforms a LLM into a classifier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6de04820f9fb2648",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Classification with the *Text completion* API\n",
    "Using the text completion API, the prompt looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adce89b43fb5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Classify the text into neutral, negative, or positive.\n",
    "Output format: one of the above classes.\n",
    "\n",
    "Text: I think the food was okay.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=os.environ[\"GPT_35_TURBO_INSTRUCT_MODEL_NAME\"],\n",
    "    prompt=text,\n",
    ")\n",
    "completion = response.choices[0].text.strip()\n",
    "print(completion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3ccd7a09be11f66",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Classification with the *Chat* API\n",
    "Using the chat API, the prompt looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233b412d97b158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Classify the user messages into neutral, negative, or positive. Respond only with one of the above classes.\"\n",
    "text = \"I think the food was okay.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=os.environ[\"GPT_35_CHAT_MODEL_NAME\"],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ],\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24a4d362165f5bcb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Text summarization\n",
    "We can also use the LLM to summarize text. Here we show an example of summarization prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8345a1fc9305821",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Text summarization with the *Text completion* API\n",
    "Using the text completion API, the prompt looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26efc3ab0089f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Extract the names of locations in the following text.\n",
    "Desired format:\n",
    "Places: Comma separated list of location_names\n",
    "Input: In Paris, love's embrace ignites the night, Venice's canals whisper secrets in moonlight, Berlin's walls echo stories of resilience and might\n",
    "Places: \"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=os.environ[\"GPT_35_TURBO_INSTRUCT_MODEL_NAME\"],\n",
    "    prompt=text,\n",
    "    temperature=0.0,\n",
    ")\n",
    "completion = response.choices[0].text.strip()\n",
    "places = completion.split(\",\")\n",
    "print(places)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "552f4b91abf908d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Text summarization with the *Chat* API\n",
    "Using the chat API, the prompt looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cca58b1a902fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Extract the names of locations from the user message.\n",
    "Response format: Comma separated list of location_names\n",
    "\"\"\"\n",
    "\n",
    "user_message = \"In Paris, love's embrace ignites the night, Venice's canals whisper secrets in moonlight, Berlin's walls echo stories of resilience and might\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.environ[\"GPT_35_CHAT_MODEL_NAME\"],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "completion = response.choices[0].message.content.strip()\n",
    "places = completion.split(\",\")\n",
    "print(places)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81b635b81d23186f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Chain of thought reasoning\n",
    "For more complex reasoning tasks, we can use the [chain of thought reasoning technique](https://www.promptingguide.ai/techniques/cot#chain-of-thought-cot-prompting). In this prompt, the LLM first generates a thought by writing down its observations, reasoning, and calculations. Then, it writes down the answer after the `Answer:`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59d39d064bdf65de",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Chain of thought reasoning with the *Text completion* API\n",
    "Using the text completion API, the prompt looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46127d1440f6d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "You solve mathematical problems by writing down your reasoning and calculations and then writing down the answer.\n",
    "\n",
    "Respond using this format:\n",
    "Thought: describe here you write reasoning, and calculations need to solve the problem\n",
    "Answer: your answer without any explanation, text or calculations.\n",
    "\n",
    "\n",
    "Problem: I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1.\n",
    "Thought:\"\"\".strip()\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=os.environ[\"GPT_35_TURBO_INSTRUCT_MODEL_NAME\"],\n",
    "    prompt=text,\n",
    "    temperature=0.0,\n",
    "    max_tokens=1024\n",
    ")\n",
    "completion = response.choices[0].text.strip()\n",
    "print(completion)\n",
    "answer = completion.split(\"Answer:\")[1].strip()\n",
    "print(\"#\" * 80)\n",
    "print(\"Extracted answer:\", answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7e26712e6e87980",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Chain of though reasoning with the *Chat* API\n",
    "Using the chat API, the prompt looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab6ee5d5d33f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "The user will give you mathematical problems to solve.\n",
    "You should solve the problems and respond with the answer.\n",
    "Respond using this format:\n",
    "Thought: describe here you write reasoning, and calculations need to solve the problem\n",
    "Answer: your answer without any explanation, text or calculations.\n",
    "\"\"\".strip()\n",
    "\n",
    "user_message = \"\"\"\n",
    "I went to the market and bought 10 apples. \n",
    "I gave 2 apples to the neighbor and 2 to the repairman. \n",
    "I then went and bought 5 more apples and ate 1.\n",
    "How many apples did I remain with?\n",
    "\"\"\".strip()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.environ[\"GPT_35_CHAT_MODEL_NAME\"],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")\n",
    "completion = response.choices[0].message.content.strip()\n",
    "# Here we extract the answer from the completion by splitting the text on the Answer: keyword\n",
    "# and taking the part after the keyword.\n",
    "answer = completion.split(\"Answer:\")[1].strip()\n",
    "print(completion)\n",
    "print(\"#\" * 80)\n",
    "print(\"Extracted answer:\", answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b9cce06765fe8ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Few shot examples\n",
    "Few shot examples are another useful technique to guide the LLM to generate a specific output.\n",
    "It is especially useful when it easier to just show the desired format, instead of describing it.\n",
    "\n",
    "In the Chat API, we can implement this by writing our own `assistant` messages. This prompt looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0944759a5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=os.environ[\"GPT_35_CHAT_MODEL_NAME\"],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Posible values for sentiment: neutral, negative, good\"},\n",
    "        {\"role\": \"user\", \"content\": \"I think the food was okay.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sentiment: neutral\"},\n",
    "        {\"role\": \"user\", \"content\": \"I think the food was bad.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sentiment: negative\"},\n",
    "        {\"role\": \"user\", \"content\": \"I think the food was good.\"},\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")\n",
    "completion = response.choices[0].message.content.strip()\n",
    "print(completion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ee8309573a5b2bf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extracting housing information\n",
    "Now that we have seen some examples of prompt engineering, let's apply them to extract information from a dataset of housing descriptions. \n",
    "\n",
    "We have a dataset with house listing descriptions. This description contains information about the house, such as the number of bedrooms, the neighborhood, and whether pets are allowed. However, everybody writes the information slightly differently, making it hard to parse it using regular expressions. Let's try to use the LLM to extract this information.\n",
    "\n",
    "We have also included the known answer for each example in the dataset. This makes it easier to evaluate your solution, although in practice, we would not have this information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ed01463c5d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"houses.csv\")\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bdd68b3aeb3b91",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As you can see, we have the following information available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764e92261ea6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_idx = 0\n",
    "row = df.iloc[house_idx]\n",
    "print(\"House:\", house_idx)\n",
    "print(\"City:\", row[\"city\"])\n",
    "print(\"Price:\", row[\"price\"])\n",
    "print(\"Surface area:\", row[\"surface_area\"])\n",
    "print(\"Bedrooms:\", row[\"bedrooms\"])\n",
    "print(\"Description:\\n\", row[\"description\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88a0ed04302f9afc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1b: Extract the number of bedrooms\n",
    "The first thing we want to extract is the number of bedrooms.\n",
    "This should be a positive integer number.\n",
    "It is your task to write a prompt that extracts this information from the description in the function below.\n",
    "\n",
    "For example:\n",
    "- Description: \"The house has 3 bedrooms and two bathrooms.\"\n",
    "- Extracted number: \"3\"\n",
    "\n",
    "If you run this cell, it will automatically test your function against the known correct answers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bb348ce18f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_n_bedrooms(description: str) -> str:\n",
    "    # YOUR CODE HERE START\n",
    "    system_prompt = \"\"\"\n",
    "    The user sends a description of a house. Extract the number bedrooms room from the description.\n",
    "    Respond only with the an integer number for the number bedrooms room from the description. \n",
    "    Do not include any other text or other information like explanation in the response.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE END\n",
    "    \n",
    "    # Feel free to change more of the code below if you want to\n",
    "    # This is just a skeleton to get you started\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.environ[\"GPT_35_CHAT_MODEL_NAME\"],\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            # YOUR CODE HERE START: Optionally add some few shot examples here\n",
    "            {\"role\": \"user\", \"content\": \"The house has 3 bedrooms and two bathrooms.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"3\"},\n",
    "            # YOUR CODE HERE END\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Here we test your function against the known correct answers\n",
    "# Feel free to inspect df[\"bedrooms\"] to get a better understanding go the answers.\n",
    "for i, row in df.iterrows():\n",
    "    n_bedrooms = extract_n_bedrooms(row[\"description\"])\n",
    "    assert n_bedrooms.isdigit() or isinstance(n_bedrooms, float), f\"For row {i}, we got not a number: {n_bedrooms}\"\n",
    "    assert row[\"bedrooms\"] == int(n_bedrooms), f\"For row {i}, we expected {row['bedrooms']} but got {n_bedrooms}\"\n",
    "    print(f\"✅ Row {i} passed `{n_bedrooms}` == `{row['bedrooms']}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25ef1e2a7342019f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1c: Extract neighborhood name\n",
    "The second thing we want to extract is the name of the neighborhood.\n",
    "This should be a string with the name of the neighborhood.\n",
    "It is your task to write a prompt that extracts this information from the description in the function below.\n",
    "\n",
    "For example:\n",
    "- Description: \"The house is located in De Pijp.\"\n",
    "- Extracted neighborhood: \"De Pijp\"\n",
    "\n",
    "If you run this cell, it will automatically test your function against the known correct answers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b49d7963a57b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_neighborhood(description):\n",
    "    # YOUR CODE HERE START\n",
    "    system_prompt = \"\"\"\n",
    "    The user sends a description of a house. Extract the name of the neighborhood from the description.\n",
    "    Respond only with the name of the neighborhood, do not include any other text or other information like the city name.\n",
    "    Respond with unknown if the neighborhood name is not mentioned in the description.\n",
    "    No trailing spaces or punctuation.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE END\n",
    "    \n",
    "    # Feel free to change more of the code below if you want to\n",
    "    # This is just a skeleton to get you started\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.environ[\"GPT_35_CHAT_MODEL_NAME\"],\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "             # YOUR CODE HERE START: Optionally add some few shot examples here\n",
    "             # YOUR CODE HERE END\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    message = response.choices[0].message.content\n",
    "    \n",
    "    return message.replace(\".\", \"\").strip()\n",
    "\n",
    "# Here we test your function against the known correct answers\n",
    "# Feel free to inspect df[\"neighborhood\"] to get a better understanding go the answers.\n",
    "for i, row in df.iterrows():\n",
    "    neighborhood_name = extract_neighborhood(row[\"description\"])\n",
    "    assert neighborhood_name.lower().strip() == row[\"neighborhood\"].lower().strip(), f\"For row {i}, we expected `{row['neighborhood']}` but got `{neighborhood_name}`\"\n",
    "    print(f\"✅ Row {i} passed {neighborhood_name} == {row['neighborhood']}\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68c18950e0e42f6f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1d: Extract if pets are allowed\n",
    "The last thing we want to extract is whether pets are allowed.\n",
    "This can be one of the following classes:\n",
    "- `allowed`: If the description explicitly mentions that pets are allowed.\n",
    "- `not_allowed`: If the description explicitly mentions that pets are not allowed.\n",
    "- `unknown`: If the description does not explicitly mention whether pets are allowed or not.\n",
    "\n",
    "It is your task to write a prompt that extracts this information from the description in the function below.\n",
    "\n",
    "For example:\n",
    "- Description: \"No dogs allowed.\"\n",
    "- Extracted: \"not_allowed\"\n",
    "\n",
    "If you run this cell, it will automatically test your function against the known correct answers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923bb17eba43d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_pets_allowed(description):\n",
    "    # YOUR CODE HERE START\n",
    "    system_prompt = \"\"\"\n",
    "    The user sends a description of a house. Classify the text with following lables:\n",
    "    - allowed: If the description explicitly mentions that pets are allowed.\n",
    "    - not_allowed: If the description explicitly mentions that pets are not allowed.\n",
    "    - unknown: If the description does not explicitly mention whether pets are allowed or not.\n",
    "\n",
    "    Format your response as follows:\n",
    "    Thought: describe here your reasoning.\n",
    "    Answer: one of the above classes\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE END\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.environ[\"GPT_35_CHAT_MODEL_NAME\"],\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            # YOUR CODE HERE START: Optionally, add some few shot examples here\n",
    "            # YOUR CODE HERE END\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    message = response.choices[0].message.content\n",
    "    # YOUR CODE HERE START: Parse the response\n",
    "    return message.lower().split(\"answer:\")[1].strip().replace(\".\", \"\")\n",
    "    # YOUR CODE HERE END\n",
    "\n",
    "# Here we test your function against the known correct answers\n",
    "# Feel free to inspect df[\"neighborhood\"] to get a better understanding go the answers.\n",
    "for i, row in df.iterrows():\n",
    "    pets_allowed = are_pets_allowed(row[\"description\"])\n",
    "    assert pets_allowed in [\"allowed\", \"not_allowed\", \"unknown\"], f\"For row {i}, we got unexpected class: {pets_allowed}\"\n",
    "    assert pets_allowed == row[\"pets_allowed\"], f\"For row {i}, we expected {row['pets_allowed']} but got {pets_allowed}\"\n",
    "    print(f\"✅ Row {i} passed {pets_allowed} == {row['pets_allowed']}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6bdef0ae809b952",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1e: Reflection\n",
    "So far, we have implemented multiple functions that each extract some information from the description.\n",
    "Before we continue, let's reflect on the current approach.\n",
    "- What are the disadvantages of the current approach with separate functions for each extraction task? \n",
    "- How could we improve the current approach?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a34f984ab0f285e1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Optional exercise 1f: Combine all the extraction methods into a single prompt\n",
    "Let's try to combine all the extraction methods into a single function.\n",
    "It is your task to write a prompt that extracts this information from the description in the function below.\n",
    "\n",
    "For example:\n",
    "- Description: \"This is a 3 bedrooms house in De Pijp where pets are not allowed.\"\n",
    "- Extracted: `{\"n_bedrooms\": 3, \"neighborhood\": \"De Pijp\", \"pets_allowed\": \"not_allowed\"}`\n",
    "\n",
    "If you run this cell, it will automatically test your function against the known correct answers in the dataset.\n",
    "\n",
    "Note: might need the [json.load](https://docs.python.org/3/library/json.html) function to parse a JSON string into a Python dictionary.\n",
    "\n",
    "Note: In the Chat API, setting `response_format={\"type\": \"json_object\"}` guarantees the ouput is a JSON (although it doesn't guarantee it will be the format we want!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f67ede0341252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any\n",
    "def extract_info(description: str) -> dict[str, Any]:\n",
    "    # YOUR CODE HERE START\n",
    "    system_prompt = \"\"\"\n",
    "    The user sends a description of a house. Extract the number bedrooms room, the name of the neighborhood, and whether pets are allowed from the description.\n",
    "\n",
    "    Your response should be a JSON object with the following format:\n",
    "    {\n",
    "    “n_bedrooms”: … # a positive integer no other text\n",
    "    “neighborhood”: … # Name of the neighborhood no other text\n",
    "    “pets_allowed”: … # allowed/not_allowed/unknown Use unknown if the description does not explicitly mention whether pets are allowed or not.\n",
    "    }\n",
    "    \"\"\".strip()\n",
    "    # YOUR CODE HERE END\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.environ[\"GPT_35_CHAT_MODEL_NAME\"],\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            # YOUR CODE HERE START: Optionally add some few shot examples here\n",
    "            # YOUR CODE HERE END\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    \n",
    "    # YOUR CODE HERE START: Parse the response\n",
    "    data = json.loads(response.choices[0].message.content)\n",
    "    # YOUR CODE HERE END\n",
    "    \n",
    "    return data\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    info = extract_info(row[\"description\"])\n",
    "    assert info[\"n_bedrooms\"] == row[\"bedrooms\"], f\"For row {i}, we expected {row['bedrooms']} but got {info['n_bedrooms']}\"\n",
    "    assert info[\"neighborhood\"].lower().strip() == row[\"neighborhood\"].lower().strip(), f\"For row {i}, we expected `{row['neighborhood']}` but got `{info['neighborhood']}`\"\n",
    "    assert info[\"pets_allowed\"] == row[\"pets_allowed\"], f\"For row {i}, we expected {row['pets_allowed']} but got {info['pets_allowed']}\"\n",
    "    print(f\"✅ Row {i} passed {info}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
