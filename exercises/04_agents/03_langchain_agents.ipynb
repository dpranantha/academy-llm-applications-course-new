{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Langchain agents\n",
    "\n",
    "LangChain provides [various kinds of agents](https://python.langchain.com/docs/modules/agents/agent_types/). These agents have the capability to initiate actions and autonomously decide when and in what sequence to perform them. This enables users to rapidly and effectively implement a reasoning agent for a range of different contexts.\n",
    "\n",
    "In this exercise we\u2019ll examine a few of the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload imports\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_in_production.openai_utils import get_openai_client\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import load_tools, create_openai_tools_agent, AgentExecutor, create_react_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Here we create the client.\n",
    "client = get_openai_client(use_langchain=True, model_name=os.environ[\"GPT_4_MODEL_NAME\"], temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by creating some tools the LangChain agents can use.\n",
    "\n",
    "LangChain has a number of inbuilt tools. For example,\n",
    "- `arxiv`: A search tool for papers on the [arXiv](https://arxiv.org) website\n",
    "- `dalle-image-generator`: A tool for creating images with Dall-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "    [\"arxiv\", \n",
    "    #  \"dalle-image-generator\"\n",
    "     ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can conveniently create custom tools with the [`@tools` decorator](https://python.langchain.com/docs/modules/agents/tools/custom_tools#tool-decorator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_weather(location: str) -> dict:\n",
    "    \"\"\"Get the current weather conditions in a given location\n",
    "\n",
    "    :param location: The city (and state), e.g. \"San Francisco, CA\"\n",
    "    :return: The weather conditions\n",
    "    \"\"\"\n",
    "    return requests.get(\n",
    "        f\"https://api.weatherapi.com/v1/current.json?key={os.environ['WEATHER_API_KEY']}&q={location}\"\n",
    "    ).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_current_weather.name)\n",
    "print(get_current_weather.description)\n",
    "print(get_current_weather.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(get_current_weather)\n",
    "tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Tool calling\n",
    "\n",
    "One of the more simple agents we can create with LangChain is an Agent that uses OpenAI Tool calling.\n",
    "\n",
    "As we have seen, OpenAI models have now been fine-tuned to detect when one or more function(s) should be called and respond with the inputs that should be passed to the function(s)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialise LangChain's OpenAI Tool Calling agent we require:\n",
    "- an LLM\n",
    "- Tools\n",
    "- a Prompt to guide the agent (we will use the default prompt for tool calling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "print(prompt.messages[0].prompt.template)\n",
    "\n",
    "agent = create_openai_tools_agent(client, tools, prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent is responsible for taking in input and deciding what actions to take. Crucially, the Agent does not execute those actions - that is done by the AgentExecutor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the agent on a few queries! Note that for now, these are all stateless queries (it won\u2019t remember previous interactions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"input\": \"Is it raining in Paris?\"}\n",
    "\n",
    "response = agent_executor.invoke(input)\n",
    "response['output']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3a: ReAct paper\n",
    "\n",
    "Use the agent that we've created to find out which paper initially introduced the idea of ReAct prompting for LLMs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE START\n",
    "# YOUR CODE HERE END"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReAct can also be implemented easily with LangChain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we need an LLM, tools and a prompt to implement the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "print(prompt.template)\n",
    "agent = create_react_agent(client, tools, prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create an AgentExecutor and invoke a response to an input prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, return_intermediate_steps=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"input\": \"Is it raining in Paris?\"}\n",
    "\n",
    "response = agent_executor.invoke(input)\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['intermediate_steps'][0][0].log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Agent\n",
    "\n",
    "LangChain has a [libary of agents that are optimised for specific tasks](https://python.langchain.com/docs/integrations/toolkits). For example, the Pandas agent."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate the Pandas agent on the Chickweight dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chickweight = pd.read_csv(\"chickweight.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent requires a model and a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(client, chickweight, verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can invoke queries directly to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\"How many columns are there?\")\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\"What is the maximum value in the weight column?\")\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\"Can you return the weight column as a list?\")\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}