{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Assistants\n",
    "\n",
    "OpenAI's Assistants API is designed to help developers build powerful AI assistants capable of performing a variety of tasks.\n",
    "\n",
    "- Assistants can call [models](https://platform.openai.com/docs/models) with specific instructions to tune their personality and capabilities.\n",
    "- Assistants can access **multiple tools in parallel**. These can be native tools, like `code_interpreter` or `file_search`, or custom tools you build (via function calling).\n",
    "- Assistants can access persistent **Threads**. Threads simplify AI application development by storing message history and truncating it when the conversation gets too long for the model\u2019s context length. You create a Thread once, and simply append Messages to it as your users reply.\n",
    "- Assistants can access files in several formats. When using tools, Assistants can also create files (e.g., images, spreadsheets, etc) and reference them in the Messages they create.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_in_production.openai_utils import get_openai_client\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# This reads the .env file in your project and transforms its content into env variables.\n",
    "# This way you don't have to hard code your secrets.\n",
    "dotenv.load_dotenv()\n",
    "# Here we create the client.\n",
    "client = get_openai_client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Overview of Assistants\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"../../assets/diagram-assistant.webp\" width=800 align=center />\n",
    "</p>\n",
    "\n",
    "| OBJECT     | WHAT IT REPRESENTS                                                                                             |\n",
    "|------------|---------------------------------------------------------------------------------------------------------------|\n",
    "| Assistant  | Purpose-built AI that uses OpenAI\u2019s models and calls tools                                                    |\n",
    "| Thread     | A conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a model\u2019s context. |\n",
    "| Message    | A message created by an Assistant or a user. Messages can include text, images, and other files. Messages stored as a list on the Thread.           |\n",
    "| Run        | An invocation of an Assistant on a Thread. The Assistant uses its configuration and the Thread\u2019s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.        |\n",
    "| Run Step   | A detailed list of steps the Assistant took as part of a Run. An Assistant can call tools or create Messages during its run. Examining Run Steps allows you to introspect how the Assistant is getting to its final results.  |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Assistants\n",
    "\n",
    "To get started, creating an Assistant only requires specifying the model to use. But you can further customize the behavior of the Assistant:\n",
    "\n",
    "- Use the `instructions` parameter to guide the personality of the Assistant and define its goals. Instructions are similar to system messages in the Chat Completions API.\n",
    "- Use the `tools` parameter to give the Assistant access to native tools, like `code_interpreter` and `file_search`, or call a custom via function calling.\n",
    "- Use the `tool_resources` parameter to give the tools like `code_interpreter` and `file_search` access to files. Files are uploaded using the `file` upload endpoint and must have the purpose set to assistants to be used with this API.\n",
    "\n",
    "For example, to create an Assistant that can create data visualization based on a .csv file, first upload a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file=open(\"chickweight.csv\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create the Assistant, with the `code_interpreter` tool enabled and provide the file as a resource to the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Data visualizer\",\n",
    "  description=\"You are great at creating beautiful data visualizations. You analyze data present in .csv files, understand trends, and come up with data visualizations relevant to those trends. You also share a brief text summary of the trends observed.\",\n",
    "  model=os.environ[\"GPT_4_MODEL_NAME\"],\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  tool_resources={\n",
    "    \"code_interpreter\": {\n",
    "      \"file_ids\": [file.id]\n",
    "    },\n",
    "  }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Threads and Messages\n",
    "\n",
    "Threads and Messages represent a conversation session between an Assistant and a user. There is no limit to the number of Messages you can store in a Thread. Once the size of the Messages exceeds the context window of the model, the Thread will attempt to smartly truncate messages, before fully dropping the ones it considers the least important.\n",
    "\n",
    "You can create a Thread with an initial list of Messages like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Create 3 data visualizations based on the trends in this file.\",\n",
    "      \"attachments\": [\n",
    "        {\n",
    "          \"file_id\": file.id,\n",
    "          \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messages can contain text, images, or file attachments. Message `attachments` are helper methods that add files to a thread's `tool_resources`. You can also choose to add files to the `thread.tool_resources` directly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a thread"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can initate an assistant with a thread like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  #instructions=\"New instructions\" #You can optionally provide new instructions but these will override the default instructions\n",
    ")\n",
    "print(run.status)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the complexity of the query you run, the thread could take longer to execute. In that case you can create a loop to monitor the run status of the thread with code like the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "status = run.status\n",
    "\n",
    "while status not in [\"completed\", \"cancelled\", \"expired\", \"failed\"]:\n",
    "    time.sleep(5)\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = run.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Status: {status}')\n",
    "print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a Run is `in_progress` or in other nonterminal states the thread is locked. When a thread is locked new messages can't be added, and new runs can't be created."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the run status indicates successful completion, you can list the contents of the thread again to retrieve the model's and any tools response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ") \n",
    "\n",
    "print(messages.model_dump_json(indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving files\n",
    "\n",
    "We had requested that the model generate three images from the dataset. In order to download the images, we first need to retrieve the images' file IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(messages.model_dump_json(indent=2))  # Load JSON data into a Python object\n",
    "\n",
    "image_ids = []\n",
    "\n",
    "for i in range(3):\n",
    "    image_ids.append(data['data'][0]['content'][i]['image_file']['file_id'])\n",
    "\n",
    "image_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then download the images and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(image_ids), figsize=(12,16))\n",
    "for i, id in enumerate(image_ids):\n",
    "    content = client.files.content(id)\n",
    "    content.write_to_file(f\"{i}.png\")\n",
    "    img = mpimg.imread(f\"{i}.png\")\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a follow-up question on the thread\n",
    "\n",
    "We can add follow-up questions if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Show me the code you used to generate the graphs\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we'll need to run the thread and wait for it to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  #instructions=\"New instructions\" #You can optionally provide new instructions  but these will override the default instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "status = run.status\n",
    "while status not in [\"completed\", \"cancelled\", \"expired\", \"failed\"]:\n",
    "    time.sleep(5)\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = run.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Status: {status}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the run status reaches completed, we'll list the messages in the thread again which should now include the response to our latest question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages.model_dump_json(indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract only the response to our latest question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(messages.model_dump_json(indent=2))\n",
    "code = data['data'][0]['content'][0]['text']['value']\n",
    "print(code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4a: Dark-mode\n",
    "\n",
    "Add another question to the thread to see if the code interpreter can swap the charts to dark mode."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part i: Add a user question to the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    # YOUR CODE HERE START\n",
    "    # YOUR CODE HERE END\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part ii: Run the thread and wait for it to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the thread\n",
    "run = client.beta.threads.runs.create(\n",
    "  # YOUR CODE HERE START\n",
    "  # YOUR CODE HERE END\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the task has completed\n",
    "# YOUR CODE HERE START\n",
    "# YOUR CODE HERE END\n",
    "\n",
    "print(f'Status: {status}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part iii: Get the Assistants messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Assitant's messages\n",
    "messages = client.beta.threads.messages.list(\n",
    "  # YOUR CODE HERE START \n",
    "# YOUR CODE HERE END\n",
    ")\n",
    "\n",
    "print(messages.model_dump_json(indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the updated graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(messages.model_dump_json(indent=2))  # Load JSON data into a Python object\n",
    "\n",
    "fig, axs = plt.subplots(1, len(image_ids), figsize=(12,16))\n",
    "for i in range(3):\n",
    "    id = data['data'][0]['content'][i]['image_file']['file_id']\n",
    "    content = client.files.content(id)\n",
    "    content.write_to_file(f\"{i}_dark.png\")\n",
    "    img = mpimg.imread(f\"{i}_dark.png\")\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}