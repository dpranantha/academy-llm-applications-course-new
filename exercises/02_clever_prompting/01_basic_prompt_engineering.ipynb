{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fdcd6e0a3ab320c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 1 - Basic prompt engineering\n",
    "The goal of this exercise is to become familiar with the basic prompt engineering techniques.\n",
    "We do this by first interactively exploring the examples from the slides.\n",
    "Then, we will apply the same techniques to extract information from a dataset of housing descriptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a40893",
   "metadata": {},
   "source": [
    "\n",
    "To do this will make use of the cloud-agnostic **LangChain** API.\n",
    "\n",
    "## Introduction to LangChain\n",
    "\n",
    "In the previous chapter, we explored how to interact directly with language models, like OpenAI's GPT or Google's Gemini (Vertex AI). While these APIs are powerful, working with them directly can become repetitive and cloud-specific.\n",
    "\n",
    "LangChain is a Python-based framework that simplifies the use of language models, providing a cloud-agnostic interface for interacting with providers like Google Vertex AI and (Azure) OpenAI. With LangChain, you can focus on what you want the model to do, not how to interact with different APIs.\n",
    "\n",
    "**Why Use LangChain?**\n",
    "- Cloud-Agnostic: Switch between providers (e.g., OpenAI, Azure, Google) with minimal changes to your code.\n",
    "- Simplified Usage: LangChain abstracts away API-specific details, letting you use models in a more consistent and straightforward way.\n",
    "- Scalability: As your projects grow, LangChain makes it easier to manage interactions with models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6600ff9a",
   "metadata": {},
   "source": [
    "\n",
    "Let's import the necessary libraries and create a client for our LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf5960f5b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_in_production.llm import instantiate_langchain_model\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Here we create the client. \n",
    "# Make sure you select the LLM provider that corresponds to the one you are using in this course!\n",
    "client = instantiate_langchain_model(\n",
    "    # llm_provider=\"azure\",\n",
    "    # llm_provider=\"gcp\",\n",
    ")\n",
    "client.model_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14055929d19b83e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1a: Examples from the slides\n",
    "In this exercise, you can interactively re-run the examples from the slides.\n",
    "\n",
    "\n",
    "For each example, do the following:\n",
    "- First, run the example as is and observe the output.\n",
    "- Compare how using the LangChain model differs from using the cloud-specific API.\n",
    "- Next, modify the prompt and see how it affects the output.\n",
    "- Optionally, try giving it a different problem to see how it handles that as well.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be2dc1dbc2852c80",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Classification\n",
    "\n",
    "It is possible to write prompts that transform LLMs into classifers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233b412d97b158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Classify the user messages into neutral, negative, or positive. Respond only with one of the above classes.\"\n",
    "text = \"I think the food was okay.\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", text),\n",
    "]\n",
    "response = client.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8dbbcb",
   "metadata": {},
   "source": [
    "The prompt above uses a chat-style format, where a system message defines the task (classifying sentiment) and a human message provides the input text, mimicking a conversational interaction with the language model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24a4d362165f5bcb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Summarization\n",
    "\n",
    "We can also use the LLM to summarize text. Here we show an example of summarization prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26efc3ab0089f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Extract the names of locations in the following text.\n",
    "Desired format:\n",
    "Places: Comma separated list of location_names\n",
    "Input: In Paris, love's embrace ignites the night, Venice's canals whisper secrets in moonlight, Berlin's walls echo stories of resilience and might\n",
    "Places: \"\"\"\n",
    "\n",
    "response = client.invoke(\n",
    "    text\n",
    ")\n",
    "completion = response.content.strip()\n",
    "places = completion.split(\",\")\n",
    "print(places)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a24aeb",
   "metadata": {},
   "source": [
    "The above eprompt uses an instruction-following format, where a clear instruction and desired output format are provided within the input text. The language model processes the input and generates a response in the specified format, extracting location names from the given text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81b635b81d23186f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Chain of thought reasoning\n",
    "For more complex reasoning tasks, we can use the [chain of thought reasoning technique](https://www.promptingguide.ai/techniques/cot#chain-of-thought-cot-prompting). \n",
    "\n",
    "With this style, the LLM first generates a thought by writing down its observations, reasoning, and calculations. Then, it gives as final answer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59d39d064bdf65de",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Using the instruction-following format, the prompt could looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46127d1440f6d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_prompt = \"\"\"\n",
    "You solve mathematical problems by writing down your reasoning and calculations and then writing down the answer.\n",
    "\n",
    "Respond using this format:\n",
    "Thought: describe here you write reasoning, and calculations need to solve the problem\n",
    "Answer: your answer without any explanation, text or calculations.\n",
    "\n",
    "\n",
    "Problem: I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1.\n",
    "Thought:\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ef133",
   "metadata": {},
   "source": [
    "Whilst using the chat-style format could look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a2d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "The user will give you mathematical problems to solve.\n",
    "You should solve the problems and respond with the answer.\n",
    "Respond using this format:\n",
    "Thought: describe here you write reasoning, and calculations need to solve the problem\n",
    "Answer: your answer without any explanation, text or calculations.\n",
    "\"\"\".strip()\n",
    "\n",
    "user_message = \"\"\"\n",
    "I went to the market and bought 10 apples. \n",
    "I gave 2 apples to the neighbor and 2 to the repairman. \n",
    "I then went and bought 5 more apples and ate 1.\n",
    "How many apples did I remain with?\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_prompt = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38026e14",
   "metadata": {},
   "source": [
    "Compare the responses when using the instruction-following and chat-style prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.invoke(\n",
    "    # instruction_prompt,\n",
    "    chat_prompt\n",
    ")\n",
    "completion = response.content\n",
    "print(completion)\n",
    "answer = completion.split(\"Answer:\")[1].strip()\n",
    "print(\"#\" * 80)\n",
    "print(\"Extracted answer:\", answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b9cce06765fe8ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Few shot examples\n",
    "Few shot examples are another useful technique to guide the LLM to generate a specific output.\n",
    "It is especially useful when it easier to just show the desired format, instead of describing it.\n",
    "\n",
    "This way of prompting suits the chat-style format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0944759a5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.invoke(\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"Posible values for sentiment: neutral, negative, good\"},\n",
    "        {\"role\": \"user\", \"content\": \"I think the food was okay.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sentiment: neutral\"},\n",
    "        {\"role\": \"user\", \"content\": \"I think the food was bad.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sentiment: negative\"},\n",
    "        {\"role\": \"user\", \"content\": \"I think the food was good.\"},\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")\n",
    "completion = response.content.strip()\n",
    "print(completion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ee8309573a5b2bf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extracting housing information\n",
    "Now that we have seen some examples of prompt engineering, let's apply them to extract information from a dataset of housing descriptions. \n",
    "\n",
    "We have a dataset with house listing descriptions. This description contains information about the house, such as the number of bedrooms, the neighborhood, and whether pets are allowed. However, everybody writes the information slightly differently, making it hard to parse it using regular expressions. Let's try to use the LLM to extract this information.\n",
    "\n",
    "We have also included the known answer for each example in the dataset. This makes it easier to evaluate your solution, although in practice, we would not have this information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ed01463c5d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"houses.csv\")\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bdd68b3aeb3b91",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As you can see, we have the following information available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764e92261ea6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_idx = 0\n",
    "row = df.iloc[house_idx]\n",
    "print(\"House:\", house_idx)\n",
    "print(\"City:\", row[\"city\"])\n",
    "print(\"Price:\", row[\"price\"])\n",
    "print(\"Surface area:\", row[\"surface_area\"])\n",
    "print(\"Bedrooms:\", row[\"bedrooms\"])\n",
    "print(\"Description:\\n\", row[\"description\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88a0ed04302f9afc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1b: Extract the number of bedrooms\n",
    "The first thing we want to extract is the number of bedrooms.\n",
    "This should be a positive integer number.\n",
    "It is your task to write a prompt that extracts this information from the description in the function below.\n",
    "\n",
    "For example:\n",
    "- Description: \"The house has 3 bedrooms and two bathrooms.\"\n",
    "- Extracted number: \"3\"\n",
    "\n",
    "If you run this cell, it will automatically test your function against the known correct answers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bb348ce18f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_n_bedrooms(description: str) -> str:\n",
    "    # YOUR CODE HERE START\n",
    "    # YOUR CODE HERE END\n",
    "    \n",
    "    # Feel free to change more of the code below if you want to\n",
    "    # This is just a skeleton to get you started\n",
    "    response = client.invoke(\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            # YOUR CODE HERE START: Optionally add some few shot examples here\n",
    "            # YOUR CODE HERE END\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "# Here we test your function against the known correct answers\n",
    "# Feel free to inspect df[\"bedrooms\"] to get a better understanding go the answers.\n",
    "for i, row in df.iterrows():\n",
    "    n_bedrooms = extract_n_bedrooms(row[\"description\"])\n",
    "    assert n_bedrooms.isdigit() or isinstance(n_bedrooms, float), f\"For row {i}, we got not a number: {n_bedrooms}\"\n",
    "    assert row[\"bedrooms\"] == int(n_bedrooms), f\"For row {i}, we expected {row['bedrooms']} but got {n_bedrooms}\"\n",
    "    print(f\"\u2705 Row {i} passed `{n_bedrooms}` == `{row['bedrooms']}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25ef1e2a7342019f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1c: Extract neighborhood name\n",
    "The second thing we want to extract is the name of the neighborhood.\n",
    "This should be a string with the name of the neighborhood.\n",
    "It is your task to write a prompt that extracts this information from the description in the function below.\n",
    "\n",
    "For example:\n",
    "- Description: \"The house is located in De Pijp.\"\n",
    "- Extracted neighborhood: \"De Pijp\"\n",
    "\n",
    "If you run this cell, it will automatically test your function against the known correct answers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b49d7963a57b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_neighborhood(description):\n",
    "    # YOUR CODE HERE START\n",
    "    # YOUR CODE HERE END\n",
    "    \n",
    "    # Feel free to change more of the code below if you want to\n",
    "    # This is just a skeleton to get you started\n",
    "    response = client.invoke(\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "             # YOUR CODE HERE START: Optionally add some few shot examples here\n",
    "             # YOUR CODE HERE END\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    message = response.content\n",
    "    \n",
    "    return message.replace(\".\", \"\").strip()\n",
    "\n",
    "# Here we test your function against the known correct answers\n",
    "# Feel free to inspect df[\"neighborhood\"] to get a better understanding go the answers.\n",
    "for i, row in df.iterrows():\n",
    "    neighborhood_name = extract_neighborhood(row[\"description\"])\n",
    "    assert neighborhood_name.lower().strip() == row[\"neighborhood\"].lower().strip(), f\"For row {i}, we expected `{row['neighborhood']}` but got `{neighborhood_name}`\"\n",
    "    print(f\"\u2705 Row {i} passed {neighborhood_name} == {row['neighborhood']}\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68c18950e0e42f6f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1d: Extract if pets are allowed\n",
    "The last thing we want to extract is whether pets are allowed.\n",
    "This can be one of the following classes:\n",
    "- `allowed`: If the description explicitly mentions that pets are allowed.\n",
    "- `not_allowed`: If the description explicitly mentions that pets are not allowed.\n",
    "- `unknown`: If the description does not explicitly mention whether pets are allowed or not.\n",
    "\n",
    "It is your task to write a prompt that extracts this information from the description in the function below.\n",
    "\n",
    "For example:\n",
    "- Description: \"No dogs allowed.\"\n",
    "- Extracted: \"not_allowed\"\n",
    "\n",
    "If you run this cell, it will automatically test your function against the known correct answers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923bb17eba43d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_pets_allowed(description):\n",
    "    # YOUR CODE HERE START\n",
    "    # YOUR CODE HERE END\n",
    "\n",
    "    response = client.invoke(\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            # YOUR CODE HERE START: Optionally, add some few shot examples here\n",
    "            # YOUR CODE HERE END\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    message = response.content\n",
    "    # YOUR CODE HERE START: Parse the response\n",
    "    # YOUR CODE HERE END\n",
    "\n",
    "# Here we test your function against the known correct answers\n",
    "# Feel free to inspect df[\"neighborhood\"] to get a better understanding go the answers.\n",
    "for i, row in df.iterrows():\n",
    "    pets_allowed = are_pets_allowed(row[\"description\"])\n",
    "    assert pets_allowed in [\"allowed\", \"not_allowed\", \"unknown\"], f\"For row {i}, we got unexpected class: {pets_allowed}\"\n",
    "    assert pets_allowed == row[\"pets_allowed\"], f\"For row {i}, we expected {row['pets_allowed']} but got {pets_allowed}\"\n",
    "    print(f\"\u2705 Row {i} passed {pets_allowed} == {row['pets_allowed']}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6bdef0ae809b952",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1e: Reflection\n",
    "So far, we have implemented multiple functions that each extract some information from the description.\n",
    "Before we continue, let's reflect on the current approach.\n",
    "- What are the disadvantages of the current approach with separate functions for each extraction task? \n",
    "- How could we improve the current approach?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a34f984ab0f285e1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Optional exercise 1f: Combine all the extraction methods into a single prompt\n",
    "Let's try to combine all the extraction methods into a single function.\n",
    "It is your task to write a prompt that extracts this information from the description in the function below.\n",
    "\n",
    "For example:\n",
    "- Description: \"This is a 3 bedrooms house in De Pijp where pets are not allowed.\"\n",
    "- Extracted: `{\"n_bedrooms\": 3, \"neighborhood\": \"De Pijp\", \"pets_allowed\": \"not_allowed\"}`\n",
    "\n",
    "If you run this cell, it will automatically test your function against the known correct answers in the dataset.\n",
    "\n",
    "Note: might need the [json.load](https://docs.python.org/3/library/json.html) function to parse a JSON string into a Python dictionary.\n",
    "\n",
    "Note: In the Chat API, setting `response_format={\"type\": \"json_object\"}` guarantees the ouput is a JSON (although it doesn't guarantee it will be the format we want!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f67ede0341252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any\n",
    "def extract_info(description: str) -> dict[str, Any]:\n",
    "    # YOUR CODE HERE START\n",
    "    # YOUR CODE HERE END\n",
    "    response = client.invoke(\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            # YOUR CODE HERE START: Optionally add some few shot examples here\n",
    "            # YOUR CODE HERE END\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        # Optional: some models have a JSON response format which allows you to \n",
    "        # enforce the response format. Uncomment the following lines if you want to use it.\n",
    "        # response_format={\"type\": \"json_object\"}, # OpenAI or Azure\n",
    "        # response_mime_type=\"application/json\", # GCP\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    \n",
    "    # YOUR CODE HERE START: Parse the response\n",
    "    # YOUR CODE HERE END\n",
    "\n",
    "    # for every value, attempt to cast ints. Keep original value if it fails.\n",
    "    for key in data:\n",
    "        try:\n",
    "            data[key] = int(data[key])\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    info = extract_info(row[\"description\"])\n",
    "    assert info[\"n_bedrooms\"] == row[\"bedrooms\"], f\"For row {i}, we expected {row['bedrooms']} but got {info['n_bedrooms']}\"\n",
    "    assert info[\"neighborhood\"].lower().strip() == row[\"neighborhood\"].lower().strip(), f\"For row {i}, we expected `{row['neighborhood']}` but got `{info['neighborhood']}`\"\n",
    "    assert info[\"pets_allowed\"] == row[\"pets_allowed\"], f\"For row {i}, we expected {row['pets_allowed']} but got {info['pets_allowed']}\"\n",
    "    print(f\"\u2705 Row {i} passed {info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaebfc1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}