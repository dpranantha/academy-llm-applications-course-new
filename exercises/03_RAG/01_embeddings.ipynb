{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9289697bf7a467a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 1: Introduction to Embeddings\n",
    "This notebook will explore how we can represent text as vectors. \n",
    "\n",
    "We will use the [MiniLM](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) model from [HuggingFace](https://huggingface.co/) to embed the text. This model takes text (can be a single sentence or a paragraph) as input and outputs a vector of numerical features. The model is trained on a large corpus of text, and the features are optimized to capture the meaning of the text. \n",
    "\n",
    "As shown in the figures below, the model embeds the sentences into similar vectors if the sentences have a similar meaning. It does not matter that the exact words in the sentences are different. This also makes the embeddings robust to typos. \n",
    "\n",
    "![](../../assets/embedding-vectors-1.png)\n",
    "![](../../assets/embedding-vectors-2.png)\n",
    "\n",
    "In this notebook, you will explore:\n",
    "- How to measure the similarity between two embeddings.\n",
    "- How to make embeddings.\n",
    "- Which types of sentences are similar in the embedding space, and which are not.\n",
    "- How to visualize the embedding space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8390f618b2b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from llm_in_production.visualization_utils import plot_embeddings_interactively, plot_similarity_head_map\n",
    "from llm_in_production.huggingface_utils import get_device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "915f346204470321",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1a: Cosine similarity\n",
    "Before we can start embedding sentences, we need to be able to measure the similarity between two embeddings.\n",
    "\n",
    "This is most commonly done using the cosine similarity. The cosine similarity does not depend on the magnitudes of the two vectors, only on their angle: two vectors with the same orientation have a cosine similarity of 1, two vectors at 90\u00b0 have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude.\n",
    "\n",
    "![](../../assets/cosine-similarity.png)\n",
    "\n",
    "The cosine similarity is calculated as follows:\n",
    "\n",
    "$$\n",
    "\\text{cosine similarity}(a, b) = \\frac{{\\sum_{i=1}^{n} a_i \\cdot b_i}}{{\\sqrt{\\sum_{i=1}^{n} a_i^2} \\cdot \\sqrt{\\sum_{i=1}^{n} b_i^2}}}\n",
    "$$\n",
    "\n",
    "In vector format, the cosine similarity is calculated as follows:\n",
    "$$\n",
    "\\text{{cosine similarity}}(\\mathbf{a}, \\mathbf{b}) = \\frac{{\\mathbf{a} \\cdot \\mathbf{b}}}{{|\\mathbf{a}| \\cdot |\\mathbf{b}|}}\n",
    "$$\n",
    "\n",
    "Numpy has some useful functions that we can use to calculate the cosine similarity in a fast and efficient way for large vectors:\n",
    "- [np.dot](https://numpy.org/doc/stable/reference/generated/numpy.dot.html): Compute the dot product of two arrays.\n",
    "- [np.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html): vector norm.\n",
    "\n",
    "\n",
    "In this exercise, you will implement the cosine similarity function.\n",
    "We have created a function skeleton for you to fill in and some tests to check if your implementation is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2205d85ce374bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a: np.ndarray, b: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "    :param a: The first vector of shape (n_features,).\n",
    "    :param b: The second vector of shape (n_features,).\n",
    "    :return: The cosine similarity between the two vectors as numpy scalar (shape ()).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE START: compute the cosine similarity between the two vectors\n",
    "    # YOUR CODE HERE END\n",
    "\n",
    "\n",
    "assert np.isclose(cosine_similarity(np.array([1, 0]), np.array([1, 0])),1.), f\"Expected 1 but got {cosine_similarity(np.array([1, 0]), np.array([1, 0]))}\"\n",
    "assert np.isclose(cosine_similarity(np.array([1, 0]), np.array([0, 1])),0.), f\"Expected 0 but got {cosine_similarity(np.array([1, 0]), np.array([0, 1]))}\"\n",
    "assert np.isclose(cosine_similarity(np.array([1, 0]), np.array([-1, 0])), -1.), f\"Expected -1 but got {cosine_similarity(np.array([1, 0]), np.array([-1, 0]))}\"\n",
    "assert np.isclose(cosine_similarity(np.array([1, 0]), np.array([0, -1])), 0.), f\"Expected 0 but got {cosine_similarity(np.array([1, 0]), np.array([0, -1]))}\"\n",
    "assert np.isclose(cosine_similarity(np.array([1, 0]), np.array([1, 1])), 1.0 / np.sqrt(2)), f\"Expected 1/np.sqrt(2) but got {cosine_similarity(np.array([1, 0]), np.array([1, 1]))}\"\n",
    "assert np.isclose(cosine_similarity(np.array([1, 0]), np.array([1, -1])), 1/np.sqrt(2)), f\"Expected 1/np.sqrt(2) but got {cosine_similarity(np.array([1, 0]), np.array([1, -1]))}\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6ab13bf399702cf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## How to make embeddings?\n",
    "Now that we can measure the similarity between two embeddings, we can start exploring the embeddings.\n",
    "\n",
    "In this notebook, we will use the [MiniLM](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) model from [HuggingFace](https://huggingface.co/) to embed text. To make it easier to use, we have wrapped the model in a class called [HuggingFaceEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceEmbeddings.html) from LangChain. This class has two functions:\n",
    "- [embed_query](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceEmbeddings.html#langchain.embeddings.huggingface.HuggingFaceEmbeddings.embed_query): Embed a single string.\n",
    "- [embed_documents](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceEmbeddings.html#langchain.embeddings.huggingface.HuggingFaceEmbeddings.embed_documents): Embed a list of strings.\n",
    "\n",
    "First, lets create our embedding function by running the cell below. This will download the model from the HuggingFace model hub and load it into memory. This can take a while the first time you run it. However, the model will be cached on your computer, so it will be much faster the next time you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07f04534d3604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks if the accelerator is available like a GPU and if so, it will use it.\n",
    "device = get_device()\n",
    "# Here we create the embedding function that will be used to embed the sentences.\n",
    "embedding_func = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs={\"device\": get_device()})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c64287073946bbeb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that we have created the embedding function, we can use it to embed sentences using the [embed_query](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceEmbeddings.html#langchain.embeddings.huggingface.HuggingFaceEmbeddings.embed_query) function. Run the cell below to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f967683b6f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Bob just got home from work.\"\n",
    "embedding = embedding_func.embed_query(sentence)\n",
    "print(f\"The type of embedding: '{type(embedding)}\")\n",
    "print(f\"The embedding has {len(embedding)} features.\")\n",
    "print(f\"The first 10 features of the embedding: {embedding[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5c531562ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"Bob just got home from work.\" \n",
    "sentence2 = \"Bob just arrived home from day-job.\" # Same meaning as sentence1\n",
    "sentence3 = \"Cows are grazing in the field.\" # Totally different sentence\n",
    "\n",
    "embedding1 = np.array(embedding_func.embed_query(sentence1))\n",
    "embedding2 = np.array(embedding_func.embed_query(sentence2))\n",
    "embedding3 = np.array(embedding_func.embed_query(sentence3))\n",
    "print(f\"The cosine similarity between the sentence 1 and 2 is: {cosine_similarity(embedding1, embedding2)}\")\n",
    "print(f\"The cosine similarity between the sentence 1 and 3 is: {cosine_similarity(embedding1, embedding3)}\")\n",
    "print(f\"The cosine similarity between the sentence 2 and 3 is: {cosine_similarity(embedding2, embedding3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816c7680764d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Bob just got home from work.\",\n",
    "    \"Bob just arrived home from day-job.\",\n",
    "    \"Cows are grazing in the field.\",\n",
    "]\n",
    "# We can also embed multiple sentences at once.\n",
    "embeddings = np.array(embedding_func.embed_documents(sentences))\n",
    "print(f\"The type of embeddings: '{type(embeddings)}\")\n",
    "print(f\"The embeddings has a shape of: {embeddings.shape} (n_samples, n_features).\")\n",
    "\n",
    "\n",
    "print(f\"The cosine similarity between the sentence 1 and 2 is: {cosine_similarity(embeddings[0], embeddings[1])}\")\n",
    "print(f\"The cosine similarity between the sentence 1 and 3 is: {cosine_similarity(embeddings[0], embeddings[2])}\")\n",
    "print(f\"The cosine similarity between the sentence 2 and 3 is: {cosine_similarity(embeddings[1], embeddings[2])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7100042d0413a85c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Rerun the cell above a couple of times. Each time your try to change the sentances slightly. For example what happens if:\n",
    "- You change the name from Bob to Alice?\n",
    "- What happens if you make the sentences plural? \n",
    "- What happens if your introduce a typos?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38769264e001c2b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1b: Similarity matrix\n",
    "We now know how to use the [embed_query](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceEmbeddings.html#langchain.embeddings.huggingface.HuggingFaceEmbeddings.embed_query) and [embed_documents](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceEmbeddings.html#langchain.embeddings.huggingface.HuggingFaceEmbeddings.embed_documents) functions to embed sentences. So, let's put them to the test by making a similarity matrix. \n",
    "\n",
    "A similarity matrix is a matrix that shows the similarity between all the sentences in a dataset. The similarity matrix is a square matrix of shape (n_samples, n_samples). The similarity matrix is symmetric, so the similarity between sentences i and j is the same as the similarity between sentences j and i. \n",
    "\n",
    "In this exercise, you have to do the following:\n",
    "- Embed all the sentences.\n",
    "- Calculate the similarity between each sentence pair and store it in the similarity matrix (a simple for loop will do the trick).\n",
    "\n",
    "After you have implemented the code and run the cell, ask yourself the following questions:\n",
    "- Which sentences are similar and dissimilar?\n",
    "- How does the similarity matrix show this?\n",
    "- What happens if you change the sentences slightly?\n",
    "- Which type of changes cause the similarity to change the most?\n",
    "- Which type of change causes the similarity to change the least?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ac6cf21d93703",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"feline friends say\",\n",
    "    \"canine companions say\",\n",
    "    \"Bovine buddies said\",\n",
    "    \"The cat is walking in the bedroom\",\n",
    "    \"The kittens are in the bedroom\",\n",
    "    \"A dog was running across the kitchen\",\n",
    "    \"The puppies were running around in the kitchen\",\n",
    "]\n",
    "\n",
    "# Here we embed all the sentences.\n",
    "embeddings = embedding_func.embed_documents(sentences)\n",
    "# We convert the embeddings to a numpy array/matrix of shape (n_samples, n_features).\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Here we initialize the similarity matrix.\n",
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "\n",
    "# YOUR CODE HERE START: fill in the similarity matrix using cosine_similarity function\n",
    "# YOUR CODE HERE END\n",
    "\n",
    "plot_similarity_head_map(similarity_matrix, sentences, plot_title=\"Similarity matrix\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab3e3e9f5e0fa3d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Pydata Amsterdam dataset\n",
    "So far, we have only been working with toy example data. Let's try to apply what we have learned to a real-world dataset. We will use the [Pydata Amsterdam](https://amsterdam.pydata.org/) dataset for this. This dataset contains the titles, abstracts, and descriptions of all the talks at the Pydata Amsterdam conference in 2023. The dataset is stored in the [pydata.json](pydata.json) file.\n",
    "The data contains all kinds of about the venue, the speakers, the talks, etc. For this exercise, we will only use the talk data. The talks data is stored in the `talks` field. The `talks` field is a list of talk objects which has the following attributes:\n",
    "\n",
    "- title: The title of the talk. Typically, a single sentence.\n",
    "- abstract: The abstract of the talk. A short description that gets people to click on the talk page.\n",
    "- description: The description of the talk. A longer description of the talk that describes the talk's content, the audience, the prerequisites, etc. At least, that is the general idea. In practice, the abstract and description of everybody adhere to these rules.\n",
    "- speakers: A list of speakers that gave the talk.\n",
    "- duration: The duration of the talk.\n",
    "- date: The date of the talk.\n",
    "- room: The room where the talk was given.\n",
    "\n",
    "We will mainly focus on the title, abstracts and descriptions of the talks. Let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fb587c6b19361",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pydata.json\", \"r\") as f:\n",
    "    talks = json.load(f)[\"talks\"]\n",
    "    titles = [talk[\"title\"] for talk in talks]\n",
    "    abstracts = [talk[\"abstract\"] for talk in talks]\n",
    "    descriptions = [talk[\"description\"] for talk in talks]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "418985a15f27a213",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This code will print some random talks from the dataset so we can see what it looks like. Change the seed to see different talks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016774cb1cf6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "for _ in range(3):\n",
    "    talk_idx = random.randint(0, len(talks))\n",
    "    \n",
    "    print(f\"Talk #{talk_idx}\")\n",
    "    print(f\"Title: {titles[talk_idx]}\")\n",
    "    print(f\"Abstract:\")\n",
    "    print(abstracts[talk_idx])\n",
    "    print()\n",
    "    print(f\"Description:\")\n",
    "    print(descriptions[talk_idx])\n",
    "    print(\"#\" * 80)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b73e555be694d59",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 1c: Embeddings space exploration\n",
    "This exercise will explore the embedding space of the different talks. At PyData, talks are typically related to Python, data engineering, machine learning, LLMs, etc. So, we expect we can also find a similar grouping in the embedding space. In this exercise, you will do the following:\n",
    "- We will be embed some text using the `embedding_func`.\n",
    "- We then cluster the embeddings using the [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) algorithm from [scikit-learn](https://scikit-learn.org/stable/).\n",
    "- We then project the embeddings to a 2D space using [UMAP](https://umap-learn.readthedocs.io/en/latest/) from [umap-learn](https://umap-learn.readthedocs.io/en/latest/).\n",
    "- Finally, we will plot the embeddings in an interactive plot using [plotly](https://plotly.com/) to explore the embedding space and see if our hypothesis is correct.\n",
    "\n",
    "You don't need to know how the KMeans and UMAP algorithms work. We have already implemented them for you. If you are interested in how we did it, check out the `plot_embeddings_interactively` function in the [llm_in_production/visualization_utils.py](../../llm_in_production/visualization_utils.py) file.\n",
    "\n",
    "There are still some open questions left:\n",
    "- How many clusters should we use?\n",
    "- Which text should we embed? The title, abstract, description, or a combination of them?\n",
    "- Embedding the text.\n",
    "- Validating if our hypothesis is correct.\n",
    "\n",
    "In the next set of exercises, you will have to answer these questions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70042ee8b32555a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Part i: title embeddings\n",
    "In this sub-exercise, you will embed the titles of the talks and explore the embedding space. \n",
    "Your tasks are:\n",
    "- Embed the `titles` using the `embedding_func`.\n",
    "- Play around with the number of clusters and see which number of clusters gives the best results.\n",
    "- Visually inspect the embedding space and see if you recognize any clusters (e.g., Python, Data Engineering, LLMs, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9881093e8c8037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = 6\n",
    "# YOUR CODE HERE START: embed the titles using the embedding_func\n",
    "# YOUR CODE HERE END\n",
    "\n",
    "assert isinstance(title_embeddings, np.ndarray), f\"Expected numpy array but got {type(title_embeddings)}\"\n",
    "assert len(title_embeddings) == len(titles), f\"Expected {len(titles)} embeddings but got {len(title_embeddings)}\"\n",
    "\n",
    "plot_embeddings_interactively(\n",
    "    embeddings=title_embeddings, \n",
    "    titles=titles, \n",
    "    plot_title=\"Title embeddings\",\n",
    "    n_cluster=n_cluster,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4efd1b911771f5cb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Part ii: abstracts embeddings\n",
    "In this sub-exercise, you will embed the abstracts of the talks and explore the embedding space. \n",
    "Your tasks are:\n",
    "- Embed the `abstracts` using the `embedding_func`.\n",
    "- Play around with the number of clusters and see which number of clusters gives the best results.\n",
    "- Visually inspect the embedding space and see if you recognize any clusters (e.g., Python, Data Engineering, LLMs, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498550785279770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = 6\n",
    "# YOUR CODE HERE START: embed the abstracts using the embedding_func\n",
    "# YOUR CODE HERE END\n",
    "\n",
    "assert isinstance(abstract_embeddings, np.ndarray), f\"Expected numpy array but got {type(abstract_embeddings)}\"\n",
    "assert len(abstract_embeddings) == len(titles), f\"Expected {len(titles)} embeddings but got {len(abstract_embeddings)}\"\n",
    "\n",
    "plot_embeddings_interactively(\n",
    "    embeddings=abstract_embeddings, \n",
    "    titles=titles, \n",
    "    plot_title=\"Abstract embeddings\",\n",
    "    n_cluster=n_cluster\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36e05192e7525ef1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Part iii: descriptions embeddings\n",
    "In this sub-exercise, you will embed the descriptions of the talks and explore the embedding space. \n",
    "Your tasks are:\n",
    "- Embed the `descriptions` using the `embedding_func`.\n",
    "- Play around with the number of clusters and see which number of clusters gives the best results.\n",
    "- Visually inspect the embedding space and see if you recognize any clusters (e.g., Python, Data Engineering, LLMs, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cbd2c6d4c456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = 6\n",
    "# YOUR CODE HERE START: embed the descriptions using the embedding_func\n",
    "# YOUR CODE HERE END\n",
    "assert len(description_embeddings) == len(titles), f\"Expected {len(titles)} embeddings but got {len(description_embeddings)}\"\n",
    "\n",
    "plot_embeddings_interactively(\n",
    "    embeddings=description_embeddings, \n",
    "    titles=titles, \n",
    "    plot_title=\"Description embeddings\",\n",
    "    n_cluster=n_cluster\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96205b517a89906d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Part iv: combined embeddings\n",
    "In this sub-exercise, you will make a combined text of the title, abstract, and description and embed it.\n",
    "Your tasks are:\n",
    "- Combine the `title`, `abstract`, and `description` into one meaningful text. Note, it may be helpful to keep a reference to the different parts of the text, e.g. f\"title: {title}...\".\n",
    "- Embed the `combined_text` using the `embedding_func`.\n",
    "- Play around with the number of clusters and see which number of clusters gives the best results.\n",
    "- Visually inspect the embedding space and see if you recognize any clusters (e.g., Python, Data Engineering, LLMs, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0519fa8b020798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = 6\n",
    "combined_texts = []\n",
    "\n",
    "for talk_idx in range(len(talks)):\n",
    "    title = titles[talk_idx]\n",
    "    abstract = abstracts[talk_idx]\n",
    "    description = descriptions[talk_idx]\n",
    "    combined_text = ...\n",
    "    # YOUR CODE HERE START: combine the title, abstract and description into one meaningful text\n",
    "    # YOUR CODE HERE END\n",
    "    combined_texts.append(combined_text)\n",
    "    \n",
    "combined_text_embeddings = ...\n",
    "# YOUR CODE HERE START: embed the combined_text using the embedding_func and convert it to a numpy array\n",
    "# YOUR CODE HERE END\n",
    "\n",
    "assert isinstance(abstract_embeddings, np.ndarray), f\"Expected numpy array but got {type(abstract_embeddings)}\"\n",
    "assert len(combined_text_embeddings) == len(titles), f\"Expected {len(titles)} embeddings but got {len(combined_text_embeddings)}\"\n",
    "\n",
    "plot_embeddings_interactively(\n",
    "    embeddings=description_embeddings, \n",
    "    titles=titles, \n",
    "    plot_title=\"Description embeddings\",\n",
    "    n_cluster=n_cluster\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}